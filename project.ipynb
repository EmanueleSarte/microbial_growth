{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import corner\n",
    "import pickle\n",
    "import inspect\n",
    "\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from evolver import Evolver\n",
    "from models import Model3, Model1_2\n",
    "from util_funs import find_initial_params, plot_chains, print_latex_result, read_files,\\\n",
    "    filter_data, filter_file_names, get_run_id, emcee_analysis\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# True if you want to read from the dataset files, False if you want to generate the date with the model\n",
    "USE_DATASET = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_DATASET:\n",
    "    # m0, w1, w2, u, v = 3, 2, 3, 0.8, 2\n",
    "    # model = Model1_2(m0=m0, w1=w1, w2=w2, u=u, v=v)\n",
    "\n",
    "    # m0, w1, w2, u, v = 0.5, 2, 3, 0.8, 20\n",
    "    # model = Model1_2(m0=m0, w1=w1, w2=w2, u=u, v=v)\n",
    "    # model.summary(show_h=False)\n",
    "\n",
    "    # Here we define our model\n",
    "    a, b, c, d, w2, u, v = 4, 0.3, 3, 10, 0.8, 2, 3\n",
    "    m_f_i = 5\n",
    "    model = Model3(a=a, b=b, c=c, d=d, m_f=m_f_i, w2=w2, u=u, v=v)\n",
    "\n",
    "    # Plot the model\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    model.get_figure(axs[0])\n",
    "\n",
    "\n",
    "    # Here we make the model evolve (and divide)\n",
    "    n_generations = 400\n",
    "    evolver = Evolver(model=model)\n",
    "    evolver.evolve(n_generations, debug=False)\n",
    "\n",
    "    # Here we show some of the result\n",
    "    end_gen = 30\n",
    "    time, data = evolver.get_data(0, end_gen)\n",
    "    final_time, final_data = evolver.get_start_data(0, end_gen)\n",
    "\n",
    "    ptime = evolver.time[evolver.offset_start[0] : evolver.offset_end[end_gen] + 1]\n",
    "    params = evolver.params[evolver.offset_start[0] : evolver.offset_end[end_gen] + 1]\n",
    "\n",
    "    axs[1].plot(time, data[:, 0])\n",
    "    axs[1].set_title('Microbe Size')\n",
    "    axs[1].plot(final_time, final_data[:, 0], marker = 'o', linestyle = '');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use the data generated from our model to estimate the parameters \n",
    "\n",
    "if not USE_DATASET:\n",
    "    truth = evolver.model.fix_params.copy() # our parameters defined above\n",
    "    labels =  evolver.model.fix_params_label.copy()\n",
    "\n",
    "    nwalkers = 25 # number of walkers for the MCMC\n",
    "    # We add some gaussian noise to our initial parameters\n",
    "    guess = np.array(truth) + 1e-4 * np.random.randn(nwalkers, len(truth)) \n",
    "\n",
    "    spans = evolver.spans\n",
    "    params_list = []\n",
    "    for i in range(evolver.params.shape[1]): # the order is defined in the __init__ method of the model\n",
    "        params_list.append(evolver.params[:, i][:-1])\n",
    "\n",
    "\n",
    "    chain_lenght = 3000\n",
    "    discard = 1000\n",
    "    thin_number = 35\n",
    "    title=\"TITOLO\"\n",
    "    emcee_analysis(nwalkers=nwalkers, truths=truth, log_prob_fn=evolver.model.log_prob, args=(spans, *params_list),\n",
    "                   guess = guess, chain_lenght=chain_lenght, labels=labels, use_pool=True, discard=discard,\n",
    "                   thinning=thin_number, plot=True, title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### TO READ AND WRITE THE DATASET ###################\n",
    "tanouchi25c_set = pd.read_csv(\"./dataset/Tanouchi25C.csv\")\n",
    "tanouchi37c_set = pd.read_csv(\"./dataset/Tanouchi37C.csv\")\n",
    "susman18_set = pd.read_csv(\"./dataset/Susman18_physical_units.csv\")\n",
    "tanouchi25c_set.df_name = \"tanouchi25c\"\n",
    "tanouchi37c_set.df_name = \"tanouchi37c\"\n",
    "susman18_set.df_name = \"susman18\"\n",
    "\n",
    "names_to_dataset_map = {d.df_name: d for d in [tanouchi25c_set, tanouchi37c_set, susman18_set]}\n",
    "\n",
    "df = tanouchi37c_set\n",
    "WRITE_ON_FILE = True\n",
    "OUTPUT = True\n",
    "AUTO_FIND_P0 = True\n",
    "FOLDER_PATH = \"./results/\"\n",
    "DF_NAME = df.df_name\n",
    "lineages = []\n",
    "nwalkers = 25\n",
    "chain_lenght = 3000\n",
    "discard = 1000\n",
    "thin_number = 35\n",
    "model = Model3()\n",
    "run_id = get_run_id(model.__class__)\n",
    "\n",
    "\n",
    "params_mapping = {Model3: ([\"division_ratio\", \"length_final\", \"growth_rate\"],\n",
    "                           [slice(1, None), slice(None, -1), slice(1, None)])}\n",
    "\n",
    "START = False\n",
    "if USE_DATASET and START:\n",
    "\n",
    "    columns = [\"growth_rate\"]\n",
    "    df, df_deleted = filter_data(df, filter_cols=columns, show=False, remove_lineages=True)\n",
    "    print(f\"Eliminated {len(df_deleted)} rows\")\n",
    "\n",
    "    if model.__class__ == Model3:\n",
    "        a = 104.197\n",
    "        b = 0.007\n",
    "        c = 53.654\n",
    "        d = 64.138\n",
    "        w2 = 1.832\n",
    "        u = 0.928\n",
    "        v = 2.461\n",
    "\n",
    "        if AUTO_FIND_P0:\n",
    "            truths = find_initial_params(df)\n",
    "        else:\n",
    "            truths = [a, b, c, d, w2, u, v]\n",
    "    else:\n",
    "        raise ValueError(\"Specify the truth for this model\")\n",
    "\n",
    "    labels = model.fix_params_label\n",
    "\n",
    "    ndim = len(truths)\n",
    "    guess = np.array(truths) + 1e-4 * np.random.randn(nwalkers, ndim)\n",
    "\n",
    "    if not lineages:\n",
    "        lineages = list(df['lineage_ID'].unique().astype(int))\n",
    "\n",
    "    df = df[df[\"lineage_ID\"].isin(lineages)]\n",
    "\n",
    "    with open(FOLDER_PATH + f\"run_{run_id}.txt\", \"w\") as f:\n",
    "        f.write(inspect.getsource(model.log_prior))\n",
    "\n",
    "    print(f\"######## ANALYZING DATASET {DF_NAME}, RUN_ID: {run_id} ########\")\n",
    "    print(\"Initial Parameters:\")\n",
    "    print(\" \".join([f\"{l}={v:.3f}\" for v, l in zip(truths, labels)]))\n",
    "    print(\"\")\n",
    "\n",
    "    for (lin_id,), df_lin in df.groupby([\"lineage_ID\"]):\n",
    "        print(f\"DATASET {DF_NAME}, LINEAGE: {lin_id}, n data: {len(df_lin)}\")\n",
    "\n",
    "        spans = df_lin[\"generationtime\"][1:].to_numpy()\n",
    "        params_list = []\n",
    "        for param, slic in zip(*params_mapping[model.__class__]):\n",
    "            params_list.append(df_lin[param][slic].to_numpy())\n",
    "\n",
    "        title = f\"{DF_NAME}  run_id: {run_id}  lineage: {lin_id}\"\n",
    "        result = emcee_analysis(nwalkers=nwalkers, truths=truths, log_prob_fn=model.log_prob,\n",
    "                                args=(spans, *params_list), guess=guess, chain_lenght=chain_lenght,\n",
    "                                labels=labels, use_pool=True, discard=discard, thinning=thin_number,\n",
    "                                plot=OUTPUT)\n",
    "        samples, flat_samples, result_dict = result\n",
    "\n",
    "        if WRITE_ON_FILE:\n",
    "            data = {\"n_walkers\": nwalkers, \"ndim\": ndim, \"dataset\": DF_NAME, \"lineage_id\": lin_id,\n",
    "                    \"truths\": truths, \"initial_guess\": guess, \"labels\": labels,\n",
    "                    # \"spans\": spans, \"alphas\": alphas, \"kappas\": kappas, \"m_finals\": m_finals,\n",
    "                    \"samples\": samples, \"tau\": None, \"thin_number\": thin_number, \"discard\": discard,\n",
    "                    \"flat_samples\": flat_samples, \"result_dict\": result_dict, \"data_length\": len(df_lin),\n",
    "                    \"data\": [spans, *params_list],\n",
    "                    \"run_id\": run_id\n",
    "                    }\n",
    "\n",
    "            filename = f\"{DF_NAME}_run_{run_id:06}_lin_{int(lin_id):03}.bin\"\n",
    "            Path(FOLDER_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            with open(FOLDER_PATH + filename, \"wb\") as f:\n",
    "                pickle.dump(data, f)\n",
    "\n",
    "            print(\"File created: \", FOLDER_PATH + filename)\n",
    "            print(\"----------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### READ BACK THE FILE CREATED ########################\n",
    "FOLDER_PATH = \"./results/\"\n",
    "\n",
    "RUN_ID = \"864772\"\n",
    "dataset_results_dict = read_files(FOLDER_PATH, df_name=\"tanouchi37c\", run_id=RUN_ID, lineages=lineages)\n",
    "\n",
    "# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "# for _, data in dataset_results_dict.items():\n",
    "#     df_name, lin_id = data[\"dataset\"], data[\"lineage_id\"]\n",
    "#     labels, samples, flat_samples = data[\"labels\"], data[\"samples\"], data[\"flat_samples\"]\n",
    "#     result_dict, truths = data[\"result_dict\"], data[\"truths\"]\n",
    "\n",
    "#     title = f\"DATASET {df_name}, lineage {lin_id}\"\n",
    "\n",
    "#     print(title)\n",
    "#     plot_chains(samples, title=title, labels=labels)\n",
    "#     fig = corner.corner(flat_samples, labels=labels, truths=truths)\n",
    "#     fig.suptitle(title)\n",
    "#     plt.show()\n",
    "#     print_latex_result(list(result_dict.values()), labels)\n",
    "#     print(\"-------------------------------\")\n",
    "\n",
    "# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "\n",
    "lineages = []\n",
    "dataset_results_dict = read_files(FOLDER_PATH, df_name=\"tan\", run_id=301954,lineages=lineages)\n",
    "\n",
    "ROWS, COLS = 3, 3\n",
    "fig, axs = plt.subplots(ROWS, COLS, figsize=(COLS * 4, ROWS * 4))\n",
    "\n",
    "for i, data in enumerate(dataset_results_dict.values()):\n",
    "    df_name, lin_id = data[\"dataset\"], data[\"lineage_id\"]\n",
    "    labels, flat_samples = data[\"labels\"], data[\"flat_samples\"]\n",
    "    result_dict, truths = data[\"result_dict\"], data[\"truths\"]\n",
    "\n",
    "    # recall parameter order = a, b, c, d, w2, u, v\n",
    "\n",
    "    # for j in range(flat_samples.shape[1]):\n",
    "    #     nbins = int(np.sqrt(flat_samples[:, j].shape[0]))\n",
    "    #     index = (j // COLS, j % COLS)\n",
    "    #     if (index == (0,2) or index == (1,0)): continue\n",
    "    #     axs[index].hist(flat_samples[:, j], alpha=0.7, bins=nbins, label=f\"Lin {lin_id}\", density=True)\n",
    "\n",
    "    nbins = int(np.sqrt(flat_samples.shape[0]))\n",
    "\n",
    "    axs[0, 0].hist(flat_samples[:, 0], label=f\"Lin {lin_id}\", alpha=0.7,\n",
    "            bins=nbins, density=True)\n",
    "    \n",
    "    axs[0, 1].hist(flat_samples[:, 1], label=f\"Lin {lin_id}\", alpha=0.7,\n",
    "            bins=nbins, density=True)\n",
    "    \n",
    "    w1 = flat_samples[:, 0] * flat_samples[:, 1]\n",
    "    axs[0, 2].hist(w1, label=f\"Lin {lin_id}\", alpha=0.7,\n",
    "            bins=nbins, density=True)\n",
    "    \n",
    "    sigma_w1 = np.sqrt(flat_samples[:, 0]) * flat_samples[:, 1]\n",
    "    axs[1, 0].hist(sigma_w1, label=f\"Lin {lin_id}\", alpha=0.7,\n",
    "            bins=nbins, density=True)\n",
    "\n",
    "    axs[1, 1].hist(flat_samples[:, 4], label=f\"Lin {lin_id}\", alpha=0.7,\n",
    "            bins=nbins, density=True)\n",
    "    \n",
    "    axs[1, 2].hist(flat_samples[:, 4] / w1, label=f\"Lin {lin_id}\", alpha=0.7,\n",
    "            bins=nbins, density=True)\n",
    "    \n",
    "    axs[2, 0].hist(flat_samples[:, 5], label=f\"Lin {lin_id}\", alpha=0.7,\n",
    "            bins=nbins, density=True)\n",
    "    \n",
    "    axs[2, 1].hist(flat_samples[:, 6], label=f\"Lin {lin_id}\", alpha=0.7,\n",
    "            bins=nbins, density=True)\n",
    "    \n",
    "    axs[2, 2].hist(flat_samples[:, 5] / flat_samples[:, 6], label=f\"Lin {lin_id}\", alpha=0.7,\n",
    "            bins=nbins, density=True)\n",
    "    \n",
    "    \n",
    "\n",
    "for j, label in enumerate(labels):\n",
    "    nbins = int(np.sqrt(flat_samples[:, j].shape[0]))\n",
    "    index = (j // COLS, j % COLS)\n",
    "    axs[index].set_title(label)\n",
    "\n",
    "fig.suptitle(f\"DATASET {df_name}, #data: {len(dataset_results_dict)}\")\n",
    "axs[0, 0].set_title('a')\n",
    "axs[0, 1].set_title('b')\n",
    "axs[0, 2].set_title('w1 = a * b')\n",
    "axs[1, 0].set_title('sigma_w1 = sqrt(a) * b')\n",
    "axs[1, 1].set_title('w2')\n",
    "axs[1, 2].set_title('w2 / w1')\n",
    "axs[2, 0].set_title('u')\n",
    "axs[2, 1].set_title('v')\n",
    "axs[2, 2].set_title('u / v');\n",
    "\n",
    "axs[1, 0].set_title(\"w2 / w1\")\n",
    "axs[2, 1].set_title(\"u / v\");\n",
    "axs[2, 2].set_title(\"w1 = a * b\");\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "# ROWS, COLS = 2, 2\n",
    "\n",
    "# for i, (_, data) in enumerate(dataset_results_dict.items()):\n",
    "#     df_name, lin_id = data[\"dataset\"], data[\"lineage_id\"]\n",
    "#     if int(lin_id) not in [1, 2, 3] or not df_name.startswith(\"tan\"):\n",
    "#         continue\n",
    "\n",
    "#     print(\"Compatible file: \", df_name, \" lineage: \", lin_id)\n",
    "#     labels, flat_samples = data[\"labels\"], data[\"flat_samples\"]\n",
    "#     results, truths = data[\"result_dict\"], data[\"truths\"]\n",
    "#     data_length = data[\"data_length\"]\n",
    "#     # spans = data[\"data\"][\"spans\"]\n",
    "#     # alphas = data[\"data\"][\"alphas\"]\n",
    "#     # kappas = data[\"data\"][\"kappas\"]\n",
    "#     # m_finals = data[\"data\"][\"m_finals\"]\n",
    "\n",
    "#     params = {\"a\":results[\"a\"][0], \"b\":results[\"b\"][0], \"c\":results[\"c\"][0], \"d\":results[\"d\"][0],\n",
    "#               \"m_f\":1, \"w2\":results[\"w2\"][0], \"u\":results[\"u\"][0], \"v\":results[\"v\"][0]}\n",
    "#     model_test = Model3(**params)\n",
    "#     params_txt = model_test.get_params_str()\n",
    "\n",
    "#     evolver_test = Evolver(model_test)\n",
    "#     evolver_test.evolve(n_div=data_length)\n",
    "\n",
    "#     fig, axs = plt.subplots(ROWS, COLS, figsize=(COLS * 4, ROWS * 4))\n",
    "\n",
    "#     model_data = [evolver_test.spans]\n",
    "#     for i in range(evolver_test.params.shape[1]): # the order is defined in the __init__ method of the model\n",
    "#         model_data.append(evolver_test.params[:, i])\n",
    "    \n",
    "#     params_labels = [\"Lifetime\"] + model_test.var_params_label\n",
    "#     for j, value in enumerate(data[\"data\"]):\n",
    "#         nbins = int(np.sqrt(len(model_data[j])))\n",
    "\n",
    "#         index = (j // COLS, j % COLS)\n",
    "#         axs[index].hist(model_data[j], label=\"Generated\", density=True, alpha=0.7, bins=nbins)\n",
    "#         axs[index].hist(value, label=\"Lineage\", density=True, alpha=0.7, bins=nbins)\n",
    "#         axs[index].set_title(params_labels[j])\n",
    "#         axs[index].legend()\n",
    "    \n",
    "#     fig.suptitle(f\"{DF_NAME} lineage: {lin_id}, params: {params_txt}\", wrap=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = tanouchi25c_set\n",
    "# df = tanouchi37c_set\n",
    "# df = susman18_set\n",
    "df = susman18_set\n",
    "run_id = \"937761\"\n",
    "\n",
    "\n",
    "acmin = 1\n",
    "acmax = 20 + 1\n",
    "lineages = [*np.arange(10, 19)]\n",
    "fig, axs = plt.subplots(2, 1, figsize=(18, 14))\n",
    "# plt.acorr\n",
    "plt.suptitle(f\"{df.df_name}, runid: {run_id}\")\n",
    "axs[0].hlines([0], acmin, acmax - 1, colors=\"black\", lw=1)\n",
    "axs[1].hlines([0], acmin, acmax - 1, colors=\"black\", lw=1)\n",
    "axs[0].set_title(\"Alphas Autocorrelations\")\n",
    "axs[1].set_title(\"Kappas Autocorrelations\")\n",
    "\n",
    "lineages_passed = [lin for _, _, lin in filter_file_names(FOLDER_PATH, df.df_name, run_id).values()]\n",
    "\n",
    "sums = np.zeros(shape=(2, acmax - acmin))\n",
    "n_data = 0\n",
    "include_exc = False\n",
    "for (lin_id,), df_lin in df.groupby([\"lineage_ID\"]):\n",
    "    if lineages and lin_id not in lineages:\n",
    "        continue\n",
    "\n",
    "    ac_alpha_list = []\n",
    "    ac_kappa_list = []\n",
    "    for i in range(acmin, acmax):\n",
    "        a = df_lin[\"growth_rate\"][:-i]\n",
    "        b = df_lin[\"growth_rate\"][i:]\n",
    "        ac_alpha_list.append(np.corrcoef(a, b)[0, 1])\n",
    "\n",
    "        c = df_lin[\"division_ratio\"][1:][:-i]\n",
    "        d = df_lin[\"division_ratio\"][1:][i:]\n",
    "        ac_kappa_list.append(np.corrcoef(c, d)[0, 1])\n",
    "\n",
    "    passed = int(lin_id) in lineages_passed\n",
    "    if include_exc or passed:\n",
    "        sums[0, :] += ac_alpha_list\n",
    "        sums[1, :] += ac_kappa_list\n",
    "        n_data += 1\n",
    "\n",
    "    x_range = np.arange(acmin, acmax)\n",
    "    ls = \"solid\" if passed else \"dashed\"\n",
    "    axs[0].plot(x_range, ac_alpha_list, label=f\"Lin {lin_id}\", ls=ls, lw=1)\n",
    "    axs[1].plot(x_range, ac_kappa_list, label=f\"Lin {lin_id}\", ls=ls, lw=1)\n",
    "    # plt.scatter(x_range, autocorre_list, s=10)\n",
    "\n",
    "sums = sums/n_data\n",
    "text_mean = \"With excluded\" if include_exc else \"Without excluded\"\n",
    "axs[0].plot(x_range, sums[0, :], ls=\"dotted\", color=\"black\", lw=2, label=f\"Mean ({text_mean})\")\n",
    "axs[1].plot(x_range, sums[1, :], ls=\"dotted\", color=\"black\", lw=2, label=f\"Mean ({text_mean})\")\n",
    "axs[0].legend()\n",
    "axs[1].legend();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1dc0716793a58acb4a53f754119613b942ffd643eacae86bee36f7354dd7ff1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
